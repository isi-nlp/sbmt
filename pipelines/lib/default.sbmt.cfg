variables:
  rhdir: '$curr'
  rhbin: '$(variables.rhdir)/bin'
  rhlib: '$(variables.rhdir)/lib'
  rhsdir: '$curr/scripts'

language-code3:
  Arabic:               ara
  Armenian:             hye
  Bengali:              ben
  Chinese:              zho
  Dari:                 dar
  English:              eng
  Farsi:                fas
  French:               fre
  German:               ger
  Hausa:                hau
  Kinyarwanda:          kin
  Klingon:              tlh
  Malagasy:             mlg
  Spanish:              spa
  Swahili:              swa
  Tagalog:              tgl
  Tamil:                tam
  Thai:                 tha
  Urdu:                 urd
  Yoruba:               yor

source-language-code3:   $(language-code3.$(source-language))
target-language-code3:   $(language-code3.$(target-language))

rule-extraction:
  hadoop:
    home: '/home/nlg-01/chiangd/pkg/hadoop' 
    serial: false
    echo: false
  
  extractor: "$(variables.rhbin)/extract $extraction_options | $(variables.rhbin)/splitmarker 3"
  
  xrsdb: "$(variables.rhbin)"

  binarizer: "$(variables.rhbin)/decompbin -v $outdir/global-virtual-tbl"
  global-binarizer: "$(variables.rhbin)/decompbin -t $outdir/global-virtual-tbl"  
  unknown-cmd: $(variables.rhbin)/unknown_word_rules -c 1 --id-origin 600000000000 --unk-tag-file $rules/grammar.unk-tags --xrs-rule-format --native-unk '""UNK_F_HERE""' -f- -r %s
  archiver: "$(variables.rhbin)/archive_grammar -a fat-archive"
  
  extraction-options:
    option-string: "-h -M -U 7 -O -T -i -H -m 5000"
    node-limit: 1000
    compose-limit: 4
    wsd-size: 5
    subcorpora:
      core: # inherit
      mindet:
        compose-limit: 0
        wsd-size: 0
        option-string: "-h -M -U 0 -O -T -i -H -m 5000"
      full:
        compose-limit: 0 # no non-wsd composition
      lowlimit:
        compose-limit: 2
        wsd-size: 2
        node-limit: 100
  
  filter-options:
    topk: 30
    keep-min: 20
    non-lex-min: 40
  
  features:
    chi-ne:
      stage: extras
      chi: true
      active: $(rule-extraction.features.chi-ne.$(source-language-code3))
      green: "/home/nlg-01/blobs/ulf-rules/v1.8/bin/green-rules.pl -chinese"
      oldne: $curr/corpus-pipeline/steps/generate_entity_rules.pl
      ogrf: /home/nlg-01/blobs/ulf-rules/v1.8/bin/old-green-rule-filter.pl
      exec: "$curr/corpus-pipeline/steps/chi-ne -c $config -t $tmpdir"

    segmentation-lattice:
      # only active for chinese
      chi: true
      active: $(rule-extraction.features.segmentation-lattice.$(source-language-code3))
      stage: lattice
      exec: '$curr/scripts/create-ws-lattice.py < $outdir/bl-corpus > $tmpdir/lattices.seg-lattice'
      output: 'lattices.seg-lattice'
      
    morph-lattice:
      chi: False
      ara: True
      urd: False
      active: $(rule-extraction.features.morph-lattice.$(source-language-code3))
      stage: lattice
      exec: '$curr/scripts/modify_morph_lattices.py -m $curr/scripts/modify_morph_lattices.cfg < $tmpdir/lattices > $tmpdir/lattices.morph-lattice'
      output: 'lattices.morph-lattice'
    
    maroon:
      chi: true
      active: $(rule-extraction.features.maroon.$(source-language-code3))
      stage: extras
      exec: '$curr/corpus-pipeline/steps/extraswrap maroon -c $config -- $(variables.rhbin)/maroon_rules -i $rules/grammar.nt.symbols --add-headmarker'
      
    identity:
      stages:
        inline-extras:
         stage: inline-extras
         exec: '$curr/scripts/identity --xrs-baseid -100000000 --separator'
        extras:
         stage: extras
         exec: '$curr/corpus-pipeline/steps/extraswrap identity -c $config -- $curr/scripts/identity --xrs-baseid -100000000'
    
    green-rules:
      stages:
        inline-extras:
          stage: inline-extras
          exec: '$curr/scripts/dumpmatch $file'
          extension: 'green-rules'
    ne-rules:
      stages:
        inline-extras:
          stage: inline-extras
          exec: '$curr/scripts/dumpmatch $file'
          extension: 'ne-rules'
        extras:
          stage: extras
          exec: '$curr/corpus-pipeline/steps/sentid ne-rules $file -c $config'
          extension: 'ne-rules'
    
    toprules:
      stage: global-extras
      exec: '$(variables.rhbin)/toprules  --end-word "</foreign-sentence>" $rules/grammar.nt-root $rules/grammar.nt.symbols'

    gluerules:
      stages:
        global-extras: 
          stage: global-extras
          exec: '$(variables.rhbin)/glue_rules -e "</foreign-sentence>" -i $rules/grammar.nt.symbols --add-headmarker --mira-features'
        decode:
          stage: decode
          options:
              limit-syntax-length: 40
    
    global-ulf:
      stage: global-extras
      exec: 'cat $file'
      extension: 'global-ulf'
      
    xbarize:
      stage: post-process-extras
      exec: '$curr/scripts/xbarize --nt-prior $rules/grammar.nts'
      rank: 0    
    
    ruleid:
      stage: extract
      exec: "$curr/ruleset-pipeline/features/ruleid -c $config"
    
    minrules_decomp:
      stage: prefeature
      active: false
      exec: "$curr/ruleset-pipeline/features/minrules_decomp -c $config -o $outdir -t $tmpdir"
      output: [minrules, idmap]
    rulealign:
      stage: prefeature
      exec: "$curr/ruleset-pipeline/features/rulealign -c $config -o $outdir -t $tmpdir"
      output: []

    targetwords:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/targetwords $file -c $config"
      extension: targetwords
    
    unktags:
      stage: training
      exec: "$curr/ruleset-pipeline/features/unktags -c $config -o $outdir -t $tmpdir"
      tags: [ NNP, NP-C, NPB ]
      rank: 1
      output: grammar.unk-tags
    
    splitnt:
      # only active for chinese
      chi: true
      active: $(rule-extraction.features.splitnt.$(source-language-code3))
      stages:
        - stage: training
          exec: "$curr/ruleset-pipeline/features/ntsplit -o $outdir -t $tmpdir -c $config"
          output: "grammar.nt-split"
        - stage: post-process-extras
          exec: '$(variables.rhbin)/splitnt $rules/grammar.nt-split'
          rank: 2
    
    ntprior:
      stages: 
        - stage: training
          exec: "$curr/ruleset-pipeline/features/ntprior make-nt-root -o $outdir -c $config"
          output: "grammar.nt-root"
        - stage: training
          exec: "$curr/ruleset-pipeline/features/ntprior make-nts -o $outdir -c $config"
          output: "grammar.nts"
        - stage: decode
          options:
              prior-file: $rules/grammar.nts
              prior-bonus-count: 100
    
    leaflm:
      maxheight: 3
      maxwidth: 5
      active: false
      stages:
        - stage: feature
          exec: "$curr/ruleset-pipeline/features/leaflm -c $config"
        - stage: decode
          info: leaflm
          extension: leaflm
          options-exec: "$curr/decode-pipeline/scripts/write-ngram-options -p leaflm $file"

    
    distortion:
      stages:
        - stage: training
          exec: "$curr/ruleset-pipeline/features/distortion -S training -c $config"
          output: probs.label
        - stage: feature
          exec: "$curr/ruleset-pipeline/features/distortion -S feature -c $config"
          output: part.cross
          binarize: cross
        - stage: decode
          info: distortion
          options:
              distortion-prob-file: $rules/probs.label
    
    gt_prob:
      active: false
      stage: feature
      exec: "$curr/ruleset-pipeline/features/gtprob -c $config -t $tmpdir"
    
    rprob: # unsmoothed rule prob and decomposed rprob
      active: true
      stage: feature
      exec: "$curr/ruleset-pipeline/features/rprob -c $config -t $tmpdir"
    
    lef:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/lex lef $file -c $config -s $suffix"
      extension: lef
      
    lfe:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/lex lfe  $file -c $config -s $suffix"
      extension: lfe
      
    mwff:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/lex mwff $file -c $config -s $suffix"
      extension: mwff
      
    swff:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/lex swff $file -c $config -s $suffix"
      extension: swff
      
    model1nrm:
      extension: normal.t1
      stages:
        - stage: feature
          exec: "$curr/ruleset-pipeline/features/m1 normal $file -c $config -s $suffix"
          extension: normal.t1
        - stage: post-process-extras
          exec: "$curr/corpus-pipeline/steps/m1/extra-model1 normal $file -t $tmpdir -s $suffix"
          extension: normal.t1
    model1inv:
      extension: invers.t1
      stages:
        - stage: feature
          exec: "$curr/ruleset-pipeline/features/m1 inverse $file -c $config -s $suffix -s $suffix"
          extension: invers.t1
        - stage: post-process-extras
          exec: "$curr/corpus-pipeline/steps/m1/extra-model1 invers $file -t $tmpdir"
          extension: invers.t1
      
    discrete:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/discrete -c $config"
      
    trivial_cond_prob:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/condprob trivial_cond_prob -c $config"
      
    phrase_pfe:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/condprob phrase_pfe -c $config"
      
    phrase_pef:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/condprob phrase_pef -c $config"
      
    condprobdecomp:
      stage: feature
      active: false
      exec: "$curr/ruleset-pipeline/features/condprobdecomp -c $config"

    rule-length:
      stages:
        - stage: extract
          exec: "$curr/ruleset-pipeline/features/len -c $config"
          output: part.length-distributions
        - stage: decode
          info: rule-length
          options:
            rule-length-per-variable: 'false'
      
    count:
      stage: extract
      exec: "$curr/ruleset-pipeline/features/count -c $config"
      
    align:
      stage: extract
      exec: "$curr/ruleset-pipeline/features/max align -c $config"

    hwpos:
      stage: extract
      exec: "$curr/ruleset-pipeline/features/max hwpos -c $config"

    min:
      stage: extract
      exec: "$curr/ruleset-pipeline/features/max min -c $config"

    # not a real feature; adds a flag to rules that should be filtered before serializing
    filter:
      stage: extract
      active: true
      exec: "$curr/ruleset-pipeline/features/max filter -c $config"

    headmarker:
      stages:
        - stage: extract
          exec: "$curr/ruleset-pipeline/features/max headmarker -c $config"
        - stage: post-process-extras
          active: false
          exec: "$curr/scripts/add_dlmstring_to_xrs.pl --treep $(variables.rhbin)/treep --collins $curr/data/collins.rules --mark-head-xrs $(variables.rhbin)/mark_head_xrs"
          rank: 1
      
    syntax-mira:
      stage: feature
      exec: "$curr/ruleset-pipeline/features/syntax-mira -t $tmpdir -c $config"
    
    single-level-rewrite:
      stage: feature
      exec: '$curr/ruleset-pipeline/features/single-level-rewrite -c $config'
    
    weak-source-syntax:
      chi: true
      ara: true
      vectors:
        ara: "NP PP S VP SBAR ADJP WHNP PRT ADVP PRN QP"
        chi: "NP VP IP CLP QP ADVP PP ADJP LCP CP DNP DP PRN"
      active: $(rule-extraction.features.weak-source-syntax.$(source-language-code3))
      stages:
        - stage: ghkm
          exec: "$curr/ruleset-pipeline/features/weak-source-syntax $tmpdir/training.aux.map $(rule-extraction.features.weak-source-syntax.vectors.$(source-language-code3))"
          extension: weak-f-parse
        - stage: extract
          exec: "$curr/ruleset-pipeline/features/set weaksyn -c $config"
          output: part.weaksyn
    source-syntax:
      stages:
        - stage: ghkm
          exec: "$curr/ruleset-pipeline/features/add-source-syntax $tmpdir/training.aux.map"
          extension: f-parse
        - stage: extract
          exec: "$curr/ruleset-pipeline/features/max froot -c $config"
          output: part.froot
        - stage: extract
          exec: "$curr/ruleset-pipeline/features/max fvars -c $config"
          output: part.fvars
          binarize: fvars
        - stage: decode
          info: ssyn
    sentids:
      stages:
        - stage: ghkm
          exec: $curr/ruleset-pipeline/features/add-training-length
        - stage: extract
          exec: $curr/ruleset-pipeline/features/sentids -c $config
    
    weighted-count:
      stages:
        attach-weights:
          stage: ghkm
          extension: weights
          exec: $curr/ruleset-pipeline/features/add-weights $tmpdir/training.aux.map
        normal:
          stage: feature
          exec: "$curr/ruleset-pipeline/features/weightlex-via-map nrm -c $config -t $tmpdir"
          output: part.weightlex.nrm
        inverse:
          stage: feature
          exec: "$curr/ruleset-pipeline/features/weightlex-via-map inv -c $config -t $tmpdir"
          output: part.weightlex.inv
          
    weighted-morph-count:
      active: false
      stages:
        normal:
          stage: feature
          exec: "$curr/ruleset-pipeline/features/weightmorphlex-via-join nrm -c $config -t $tmpdir"
          output: part.weightmorphlex.nrm
          extension: weights # just to only turn on when weighted-count is on
        inverse:
          stage: feature
          exec: "$curr/ruleset-pipeline/features/weightmorphlex-via-join inv -c $config -t $tmpdir"
          output: part.weightmorphlex.inv
          extension: weights # just to only turn on when weighted-count is on

    provenance:
      stages:
        - stage: ghkm
          extension: tags
          exec: "$curr/ruleset-pipeline/features/add-provenance-markers $tmpdir/training.aux.map corpora genre"
        - stage: extract
          exec: "$curr/ruleset-pipeline/features/ratio corpora -c $config"
          output: part.corpora
        - stage: extract
          exec: "$curr/ruleset-pipeline/features/ratio genre -c $config"
          output: part.genre
        - stage: feature
          exec: "$curr/ruleset-pipeline/features/taglex-via-map nrm -c $config -t $tmpdir"
          output: part.taglex.nrm
        - stage: feature
          exec: "$curr/ruleset-pipeline/features/taglex-via-map inv -c $config -t $tmpdir"
          output: part.taglex.inv

    taglm:
      stage: decode
      info: taglm
      extension: taglm
      options-exec: "$curr/decode-pipeline/scripts/write-taglm-options $file"

    ngram:
      stage: decode
      info: ngram
      extension: ngram
      options-exec: "$curr/decode-pipeline/scripts/write-ngram-options $file"
    
    deplm:
      stage: decode
      info: dlm
      extension: deplm
      options-exec: "$curr/decode-pipeline/scripts/write-deplm-options 3 true $file"

    rule-head:
      active: false
      stages:
        nttag:
          stage: training
          exec: $curr/ruleset-pipeline/features/nthead --tag -c $config -t $tmpdir -o $outdir
          output: counts.symbol.headtag
        ntword:
          stage: training
          exec: $curr/ruleset-pipeline/features/nthead -c $config -t $tmpdir -o $outdir
          output: counts.symbol.headword
        dict:
          stage: dictionary
          exec: $curr/ruleset-pipeline/features/head-dict -c $config -t $tmpdir -o $outdir
          output: dict.rule-head
        decode:
          stage: decode
          info: rule-head
          options:
              # lambdas must sum to <= 1.0
              rule-head-rprob-lambda: 0.6 # if rprob lambda = 1.0, feature is equivalent to rprob
              rule-head-word-lambda: 0.2 # tag lambda is 1.0 - rprob lambda + word lambda
              rule-head-word-backoff-table: $rules/counts.symbol.headword
              rule-head-tag-backoff-table: $rules/counts.symbol.headtag
              rule-head-ignore-state: false # set to true to avoid splitting states on head
        extract:
          stage: extract
          exec: "$curr/ruleset-pipeline/features/head -c $config"
          output: part.head-distributions
        rwprob:
          stage: feature
          exec:  "$curr/ruleset-pipeline/features/rwprob -c $config -t $tmpdir"
          output: part.rwprob
        rtprob:
          stage: feature
          exec:  "$curr/ruleset-pipeline/features/rwprob -p -c $config -t $tmpdir"
          output: part.rtprob

tokenizer: cat
splitter: cat
decoder:
  max-sentence-length: 60 # sentences longer than this will be chopped up with last_resort_segmenter
  lattice-command: $curr/scripts/sent_to_lattice
  exec: $(variables.rhbin)/xrsdb_search
  options:
    merge-heap-lookahead: 10
    span-max-edges: 3000
 
  package: $curr/scripts/detok $decodehyp $origcorpus | $curr/bin/lc | $curr/scripts/xmlify-nbest -t SOURCE <(zcat $tstmaster) | gzip 
  score:
    score.out: '$(variables.rhbin)/scoreTranslation $lctokrefs -hyp $decodehyp -bleuNistVersion'
    ibmscore.out: '$(variables.rhbin)/scoreTranslation $lctokrefs -hyp $decodehyp -bleu'
    # no working implementation off of hpc.
    # i suggest this in a local config file:
    # decoder:
    #   score:
    #     nistbleu.out: null
    #     ibmbleu.out: null
    # rundecode will skip these since it cannot resolve the variable IGNOREME
    # alternatively, do not pass -E option to rundecode
    nistbleu.out: '/home/nlg-02/data07/bin/bleu.pl -i $decodehyp -if xline -metric bleuNistVersion $detokrefs'
    ibmbleu.out: '/home/nlg-02/data07/bin/bleu.pl -i $decodehyp -if xline -metric bleu $detokrefs'

visualization-options:
  min-length: 10
  max-length: 20
  terminal-punctuation: [ '.' , '!', '?' ] 
  nbest-fields:
    lm1: true
    lm2: true
    lm3: true
    glue-rule: true
    maroon: $(rule-extraction.features.maroon.active)
    rhprob: $(rule-extraction.features.rule-head.active)
    distortion: $(rule-extraction.features.distortion.active)
    rule-length: $(rule-extraction.features.rule-length.active)
  rule-fields:
    rprob: $(rule-extraction.features.rprob.active)
    gt_prob: $(rule-extraction.features.gt_prob.active)
    rawcount: true
    nonmonotone: true
    is_lexicalized: true
    phrase_pef: $(rule-extraction.features.phrase_pef.active)
    phrase_pfe: $(rule-extraction.features.phrase_pfe.active)
    taglex.nrm: $(rule-extraction.features.provenance.active)
    taglex.inv: $(rule-extraction.features.provenance.active)
    weightlex.inv: $(rule-extraction.features.weighted-count.active)
    weightlex.nrm: $(rule-extraction.features.weighted-count.active)
  
tuner:
  mira:
    exec: $curr/tune-pipeline/scripts/mira -j -o $outdir -t $tmpdir
    unit-learning-rate: 0.01
    max-learning-rate: 0.1
    exec-dir: '/home/nlg-02/pust/mira2-master3'
    max-sentence-length: 85
    bad-sentence-threshold: 0.05
    bleu-order: 4
    bleu-variant: 'IBM'
    max-epochs: 100
    omitted-features:
      - count
      - rawcount
      - foreign-length # um... why? --michael
      - hashid
      - sbtm_prob
      - size
      - value
      - u_cost
      - u_tb_cost
      - ulf # again... why? --michael
      - id
      - sentid
      - sid
    initial-weights:
      - rule-length:0.5
      - gt_prob:1
      - trivial_cond_prob:1
      - lex_pfe:1.5
      - lex_pef:1
      - lfe:1
      - lef:0.5
      - model1inv:1
      - model1nrm:0.5
      - green:-5
      - text-length:-6
      - derivation-size:-1
      - missingWord:5
      - spuriousWord:2.5
      - is_lexicalized:-0.8
      - nonmonotone:1
      - identity:6
      - unk-rule:6
      - glue-rule:7
      - lm1:1.5
      - lm2:2
      - maroon:15
      - deplm1:1
      - distortion:1
